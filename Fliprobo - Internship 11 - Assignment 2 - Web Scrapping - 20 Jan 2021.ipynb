{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job_Titles : ['Business Analyst/ Data Analyst/ MIS Executive (On Contract)', 'Data Scientist/Data Analyst-immediate', 'Data Analyst', 'Data Analyst', 'Data Analyst', 'Data Analyst', 'Data Analyst', 'Data Analyst - O2C - Bangalore', 'Business Data Analyst - Database Design/Mining', 'Data Analyst - MySQL/PostgreSQL']\n",
      "\n",
      "\n",
      "Job_Location : ['Bengaluru / Bangalore', 'Chennai, Pune, Bengaluru, Hyderabad', 'Bengaluru', 'Mumbai, Bengaluru, Hyderabad', 'Bengaluru', 'Bengaluru, Kolkata', 'Bengaluru', 'Bengaluru', 'Bengaluru', 'Pune, Mumbai, Bengaluru, Hyderabad, Noida, Jaipur']\n",
      "\n",
      "\n",
      "Company_Name : ['Schneider Electric', 'CAIA-Center For Artificial Intelligence & Advanced Analytics', 'Applied Materials', 'Cognizant Technology Solutions India Pvt Ltd', 'GlaxoSmithKline Pharmaceuticals Limited', 'Cognizant Technology Solutions India Pvt Ltd', 'Shell India Markets Private Limited', 'RANDSTAD INDIA PVT LTD', 'AugmatrixGo', 'Astegic']\n",
      "\n",
      "\n",
      "Experience_Required : ['2-5 Yrs', '0-3 Yrs', '6-11 Yrs', '2-3 Yrs', '2-7 Yrs', '3-4 Yrs', '5-8 Yrs', '2-4 Yrs', '2-5 Yrs', '5-10 Yrs']\n",
      "\n",
      "\n",
      "Lenght of Jobs_Title : 10\n",
      "Lenght of Job_Location : 10\n",
      "Lenght of Company_Name : 10\n",
      "Lenght of Experience_Required : 10\n",
      "\n",
      "\n",
      "The DataFrame for First 10 Data_Analyst Jobs on https://www.naukri.com/ is :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Analyst/ Data Analyst/ MIS Executive ...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Schneider Electric</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Data Analyst-immediate</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Mumbai, Bengaluru, Hyderabad</td>\n",
       "      <td>Cognizant Technology Solutions India Pvt Ltd</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru, Kolkata</td>\n",
       "      <td>Cognizant Technology Solutions India Pvt Ltd</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst - O2C - Bangalore</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Data Analyst - Database Design/Mining</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst - MySQL/PostgreSQL</td>\n",
       "      <td>Pune, Mumbai, Bengaluru, Hyderabad, Noida, Jaipur</td>\n",
       "      <td>Astegic</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  Business Analyst/ Data Analyst/ MIS Executive ...   \n",
       "1              Data Scientist/Data Analyst-immediate   \n",
       "2                                       Data Analyst   \n",
       "3                                       Data Analyst   \n",
       "4                                       Data Analyst   \n",
       "5                                       Data Analyst   \n",
       "6                                       Data Analyst   \n",
       "7                     Data Analyst - O2C - Bangalore   \n",
       "8     Business Data Analyst - Database Design/Mining   \n",
       "9                    Data Analyst - MySQL/PostgreSQL   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                              Bengaluru / Bangalore   \n",
       "1                Chennai, Pune, Bengaluru, Hyderabad   \n",
       "2                                          Bengaluru   \n",
       "3                       Mumbai, Bengaluru, Hyderabad   \n",
       "4                                          Bengaluru   \n",
       "5                                 Bengaluru, Kolkata   \n",
       "6                                          Bengaluru   \n",
       "7                                          Bengaluru   \n",
       "8                                          Bengaluru   \n",
       "9  Pune, Mumbai, Bengaluru, Hyderabad, Noida, Jaipur   \n",
       "\n",
       "                                        Company Name Experience Required  \n",
       "0                                 Schneider Electric             2-5 Yrs  \n",
       "1  CAIA-Center For Artificial Intelligence & Adva...             0-3 Yrs  \n",
       "2                                  Applied Materials            6-11 Yrs  \n",
       "3       Cognizant Technology Solutions India Pvt Ltd             2-3 Yrs  \n",
       "4            GlaxoSmithKline Pharmaceuticals Limited             2-7 Yrs  \n",
       "5       Cognizant Technology Solutions India Pvt Ltd             3-4 Yrs  \n",
       "6                Shell India Markets Private Limited             5-8 Yrs  \n",
       "7                             RANDSTAD INDIA PVT LTD             2-4 Yrs  \n",
       "8                                        AugmatrixGo             2-5 Yrs  \n",
       "9                                            Astegic            5-10 Yrs  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Acer\\Desktop\\Internship 11 - Project 1 - Avinash Carneiro\\chromedriver.exe\")\n",
    "\n",
    "#Specifying the url of the webpage\n",
    "url=\"https://www.naukri.com/data-analyst-jobs-in-bangalore?k=data%20analyst&l=bangalore\"\n",
    "\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url)\n",
    "\n",
    "#Lets create 4 empty lists\n",
    "Jobs_Title=[]\n",
    "Job_Location=[]\n",
    "Company_Name=[]\n",
    "Experience_Required=[]\n",
    "\n",
    "\n",
    "#Jobs_Title of first 10 jobs data on the website\n",
    "for i in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "        Jobs_Title.append(i.text)\n",
    "\n",
    "#Job_Location of first 10 jobs data on the website\n",
    "    for j in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\"):\n",
    "        Job_Location.append(j.text)\n",
    "\n",
    "#Company_Name of first 10 jobs data on the website\n",
    "    for k in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "        Company_Name.append(k.text)\n",
    "\n",
    "#Experience_Required of first 10 jobs data on the website\n",
    "    for l in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\"):\n",
    "        Experience_Required.append(l.text)\n",
    "        \n",
    "#Jobs_Title of first 10 jobs       \n",
    "Jobs_Title=Jobs_Title[0:10]\n",
    "print('Job_Titles :', Jobs_Title)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Job_Location of first 10 jobs\n",
    "Job_Location=Job_Location[0:10]\n",
    "print('Job_Location :', Job_Location)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Company_Name of first 10 jobs\n",
    "Company_Name=Company_Name[0:10]\n",
    "print('Company_Name :', Company_Name)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Experience_Required of first 10 jobs\n",
    "Experience_Required=Experience_Required[0:10]\n",
    "print('Experience_Required :', Experience_Required)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Length of the lists\n",
    "print('Lenght of Jobs_Title :', len(Jobs_Title)), print('Lenght of Job_Location :', len(Job_Location)),\n",
    "print('Lenght of Company_Name :', len(Company_Name)), print('Lenght of Experience_Required :', len(Experience_Required))\n",
    "\n",
    "import pandas as pd\n",
    "Data_Analyst=pd.DataFrame({})\n",
    "\n",
    "#Creating dataFrame to save the scraped data of Analyst jobs (job-title, job-location, company_name, experience_required)\n",
    "Data_Analyst['Job Title']=Jobs_Title\n",
    "Data_Analyst['Job Location']=Job_Location\n",
    "Data_Analyst['Company Name']=Company_Name\n",
    "Data_Analyst['Experience Required']=Experience_Required\n",
    "print(\"\\n\")\n",
    "\n",
    "print('The DataFrame for First 10 Data_Analyst Jobs on https://www.naukri.com/ is :')\n",
    "Data_Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job_Titles : ['Data Scientist/Data Analyst-immediate', 'HCL hiring Data scientist with exp in machine learning &SQL-Bangalore!', 'Data Scientist - Machine Learning', 'Data Scientist - Machine Learning', 'Data Scientist - Machine Learning', 'Senior Associate - Data Scientist/ML Engineer', 'Senior Data Scientist', 'Data Scientist - Machine Learning - Remote Working', 'Software Developer - Data Scientist / NLP / Machine Learning', 'Sr. Data Scientist']\n",
      "\n",
      "\n",
      "Job_Location : ['Chennai, Pune, Bengaluru, Hyderabad', 'Bengaluru', 'Bengaluru', 'Bengaluru', 'Bengaluru', 'Bengaluru', 'Bengaluru', 'Delhi NCR, Bengaluru, Anywhere in India', 'Bengaluru / Bangalore', 'Bengaluru']\n",
      "\n",
      "\n",
      "Company_Name : ['CAIA-Center For Artificial Intelligence & Advanced Analytics', 'HCL Technologies Limited', 'AugmatrixGo', 'BLUE YONDER INDIA PRIVATE LIMITED', 'BLUE YONDER INDIA PRIVATE LIMITED', 'Pricewaterhouse Coopers Private Limited', 'Philips India Limited', 'Doji Ltd', 'Cunesoft India Private Limited', 'NetApp']\n",
      "\n",
      "\n",
      "Job_Description : ['Dear CandidateSchedule a Telephonic Interview ( Please call for confirmation) : Mon- Sat from 11:00am to 5:00pmOR Walk-In to the Corporate office between Monday to Friday from 11:00am to 5:00pmContact person :Manigandan -+91 7299917200Shantha +91 9790993237Systech SolutionsTemple StepsTower 3, 6th Floor184-187 Anna SalaiSaidapet, Chennai 600015India (Near Little Mount Metro Station)Roles and ResponsibilitiesGreetings from CAIA !A great opportunity to enter the world of future technologies - Data Science, Analytics, AI, Data VisualizationApplications invited from all Freshers and experienced candidates aspiring to make a career in Artificial Intelligence and Advanced Analytics and Data Science.In case you are trying to shift your career to Analytics and/or AI domain please do connect with us to know more.What is needed from you?- An Educational background in any one of the following- BE/B.Tech, ME/M Tech, MSc, BSc/MSc Maths and Statistics, B Com, BCA, BSc CS, BSC IT, MSC IT, MCA- Skills relating to Mathematics/Statistics.- Natural passion towards numbers, business, coding, Analytics and Artificial Intelligence, Machine Learning, visualization- Good verbal and written communication skills- Ability to understand domains in businesses across various sectors- Freshers who wish to start their career in Analytics and AI and professionals who wish to up skill or change their domain to analytics and emerging technologies are free to apply.Selection procedure includes- Online Aptitude Test- Logical Ability Test / Written TestOn being shortlisted, you will be have to undergo a one-one discussion with our counsellor for further evaluation and processing of your Resume.What you can expect from us?You will get trained on the following modules for a period of 12-14 weeks:-SQL & PLSQL-Data Wrangling using Python-Statistics for Machine Learning,-Artificial Intelligence, Data Interpretation-Supervised & Unsupervised Learning,-NLP & Deep Learning-Cloud Data Lake-Business intelligence & Data Visualization-Simulation ProjectsWhat is the expected Outcome?At the end of the Training you are expected to be well versed with the following:- Analysis of large and complex data sets from multiple sources- Development and evaluation of data analytics models, algorithms and solutions- Understanding/implementation of ML algorithms, performance tuning and reporting- Implementation of algorithms to mine targeted data and the ability to convert data into a business story- Translation of business requirements into technical requirements; Data extraction, preparation and transformation- Identification, development and implementation of statistical techniques and algorithms that address business challenges and adds value to the organisation- Requirement Analysis and communication of findings in the form of a meaningful story with the stakeholdersCenter for Artificial Intelligence & Advanced Analytics (CAIA) focuses on the following:1. Global Research on emerging trends, technologies and applications in AI and Advanced Analytics2. Advanced Training programs for readying the future ready workforce3. Solutions to herald the futuristic lifestyle and workspaces in the field of AI and Data Science.http://www.centerforaia.com/Center for Artificial Intelligence and Advanced Analytics (Center for AIA) is the brainchild of experienced and visionary alumni of IIT Madras and Bombay. Digital leaders 5F World and Systech Solutions have joined hands to create a venture for architecting the future of society, workforce, governments and businesses. 5F World specializes in designing solutions around digital platforms and Systech Solutions has an expertise in architecting Artificial Intelligence and Advanced Analytics solutions for Fortune 500 companies through specialized programmed.5F World5F World is a leader in digital transformational journeys and has brought together the best minds in industry, academia and technology domains to develop a unique framework to transform stakeholder journeys through innovation and digitalization of businesses and education institutions.Systech SolutionsSystech Solutions is a leading organisation in Data Strategy, Management & Analytics services provider with deep technology expertise and over 20 years of industry experience. Systech Solutions helps empower clients with innovative, data-driven solutions to reimagine their enterprise and has forged partnerships with industry-leading technology providers to develop a full spectrum of data services.Websitehttp://www.centerforaia.com/https://inflexion-analytix-private-limited.business.site/?m=trueContact PersonShantha/ManigandanPhone Number9790993237 / 7299917200Emailmanigandan@centerforaia.comDesired Candidate ProfilePerks and Benefits', \"Dear Candidate,Greetings from HCL!!!We are looking for Data scientists with experience in machine learning algorithms and strong SQL experience.If you are Keen with Below Skill Set. Please do send the Updated CV with details such as current ctc, expected ctc and notice period to m_divvya@hcl.com / 8754448290.We are looking only for immediate joiners. Candidates with more than 30 days notice please don't apply.Technical Skills:Overall 5+ years of experience in advanced analytics and leading/mentoring team membersProficient in Python & SQL with minimum 2-3 years of hands on experienceSolid fundamentals, knowledge of supervised, unsupervised, reinforcement learning machine learning and deep learning algorithms, such as classifiers, cluster analysis, dimension reduction, regression, CNN, RNN, DQN, temporal difference methods, sequence modeling, probability theory, algorithm design and theory of computation, information retrievalAbility to work and execute projects on both structured and unstructured data in a big data environment • Strong at preparing data for analysis using SQL and experience working with the industry leading BI tools like Tableau, visualizing the data and executing to specificationsExperience of end to end implementation of predictive analytics projects for at least 1-3 years • Exposure to text analytics, web scraping, big data technologies and graph databases would be desirable • Exposure to visualization tools • Experience of intent to learn software domain related to VMware products and the way virtualization software/hardwarePreferred Skills:Good understanding of API connections and data pipelining • Knowledge with Natural Language Processing (e.g. word2vec, doc2vec, attention, LDA) • Understanding of different model performance metrics and hyperparameter optimization • Business Acumen, ability to translate business needs into a set of workable, specific requirements • Well versed with MS PowerPoint/VisioAbility to understand business requirements, KPIs and convert into analytical hypothesis in a structured and logical manner along with solution identification • Ability to handle multiple projects at a time in terms of multitasking, prioritization, allocation and team management • Ability to coordinate and work within multiple business units from project management perspective • Ability to work across geographies and interact with global stakeholders • Prior experience working in Agile methodologies/JIRA would be a plusWhat we are looking for:BS/BE in Computer Sciences, Math, Statistics or related field. Masters preferred.Proficient in SQL and experience with efficient processing of large data sets. Ability to write sophisticated and optimized queries against large databases • Proficient in data visualization tools such as Mode Analytics or Tableau • Proficient in Excel • Experience in statistical computing with Python/R • Ability to handle several concurrent activities with strong organizational skills and attention to detail We're team players. You'll do well if you're one too\", 'Roles and Responsibilities- Selecting features, building and optimizing classifiers using machine learning techniques- Data mining using state-of-the-art methods- Enhancing data collection procedures to include information that is relevant for building analytic systems- Processing, cleansing, and verifying the integrity of data used for analysis- Doing ad-hoc analysis and presenting results in a clear manner- Creating automated anomaly detection systems and constant tracking of its performanceSkills Required :- Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.- Experiences with one or more of the following is highly desirable: HPC/Parallelization, operationalizing ML models; cloud computing (e.g. Google Cloud, AWS, etc.); familiarity with ML frameworks such as Tensorflow, Theano, MXNet, etc- Good experience in a few of the following areas: deep neural networks, reinforcement learning, Markov Random Fields, Bayesian networks, semi-supervised learning, computer vision, image processing, signal processing, distributed computing, and/or numerical optimization- 2+ years of experience with computer vision and deep learning solutions, including image classification, object detection, segmentation, and equivalent computer vision-based vision tasks- Experience with common data science toolkits, such as R, Weka, NumPy, etc . Excellence in at least one of these is highly desirable- Proficiency in using query languages such as SQL, Hive, Pig- Good applied statistics skills, such as distributions, statistical testing, regression, etc.- Good scripting and programming skills- Data-oriented personality- B.Tech/M.Tech degree in from reputed institutes like IIT / NIT / BITS']\n",
      "\n",
      "\n",
      "Lenght of Jobs_Title : 10\n",
      "Lenght of Job_Location : 10\n",
      "Lenght of Company_Name : 10\n",
      "Lenght of Job_Description : 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The DataFrame for First 10 Data_Scientist Jobs on https://www.naukri.com/ is :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/Data Analyst-immediate</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>Dear CandidateSchedule a Telephonic Interview ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCL hiring Data scientist with exp in machine ...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>HCL Technologies Limited</td>\n",
       "      <td>Dear Candidate,Greetings from HCL!!!We are loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>Roles and Responsibilities- Selecting features...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>Roles and ResponsibilitiesUnder guidance, or i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>Roles and ResponsibilitiesThe Yantriks Data Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Associate - Data Scientist/ML Engineer</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Pricewaterhouse Coopers Private Limited</td>\n",
       "      <td>Day-to-Day ResponsibilitiesDesign and develop ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Job DescriptionAt Philips, data is in the cent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Machine Learning - Remote Wor...</td>\n",
       "      <td>Delhi NCR, Bengaluru, Anywhere in India</td>\n",
       "      <td>Doji Ltd</td>\n",
       "      <td>Please note that this role will be Remote / Ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Software Developer - Data Scientist / NLP / Ma...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Cunesoft India Private Limited</td>\n",
       "      <td>Roles and ResponsibilitiesWe are looking for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Job SummaryThis Cloud Business Operations Data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0              Data Scientist/Data Analyst-immediate   \n",
       "1  HCL hiring Data scientist with exp in machine ...   \n",
       "2                  Data Scientist - Machine Learning   \n",
       "3                  Data Scientist - Machine Learning   \n",
       "4                  Data Scientist - Machine Learning   \n",
       "5      Senior Associate - Data Scientist/ML Engineer   \n",
       "6                              Senior Data Scientist   \n",
       "7  Data Scientist - Machine Learning - Remote Wor...   \n",
       "8  Software Developer - Data Scientist / NLP / Ma...   \n",
       "9                                 Sr. Data Scientist   \n",
       "\n",
       "                              Job Location  \\\n",
       "0      Chennai, Pune, Bengaluru, Hyderabad   \n",
       "1                                Bengaluru   \n",
       "2                                Bengaluru   \n",
       "3                                Bengaluru   \n",
       "4                                Bengaluru   \n",
       "5                                Bengaluru   \n",
       "6                                Bengaluru   \n",
       "7  Delhi NCR, Bengaluru, Anywhere in India   \n",
       "8                    Bengaluru / Bangalore   \n",
       "9                                Bengaluru   \n",
       "\n",
       "                                        Company Name  \\\n",
       "0  CAIA-Center For Artificial Intelligence & Adva...   \n",
       "1                           HCL Technologies Limited   \n",
       "2                                        AugmatrixGo   \n",
       "3                  BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "4                  BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "5            Pricewaterhouse Coopers Private Limited   \n",
       "6                              Philips India Limited   \n",
       "7                                           Doji Ltd   \n",
       "8                     Cunesoft India Private Limited   \n",
       "9                                             NetApp   \n",
       "\n",
       "                                     Job Description  \n",
       "0  Dear CandidateSchedule a Telephonic Interview ...  \n",
       "1  Dear Candidate,Greetings from HCL!!!We are loo...  \n",
       "2  Roles and Responsibilities- Selecting features...  \n",
       "3  Roles and ResponsibilitiesUnder guidance, or i...  \n",
       "4  Roles and ResponsibilitiesThe Yantriks Data Sc...  \n",
       "5  Day-to-Day ResponsibilitiesDesign and develop ...  \n",
       "6  Job DescriptionAt Philips, data is in the cent...  \n",
       "7  Please note that this role will be Remote / Ho...  \n",
       "8  Roles and ResponsibilitiesWe are looking for a...  \n",
       "9  Job SummaryThis Cloud Business Operations Data...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Acer\\Desktop\\Internship 11 - Project 1 - Avinash Carneiro\\chromedriver.exe\")\n",
    "\n",
    "#Specifying the url of the webpage\n",
    "url=\"https://www.naukri.com/data-scientist-jobs-in-bangalore?k=data%20scientist&l=bangalore\"\n",
    "\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url)\n",
    "\n",
    "#Lets create 4 empty lists\n",
    "Jobs_Title=[]\n",
    "Job_Location=[]\n",
    "Company_Name=[]\n",
    "Job_Description=[]\n",
    "\n",
    "\n",
    "#Jobs_Title of first 10 jobs data on the website\n",
    "for i in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "        Jobs_Title.append(i.text)\n",
    "\n",
    "#Job_Location of first 10 jobs data on the website\n",
    "    for j in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\"):\n",
    "        Job_Location.append(j.text)\n",
    "\n",
    "#Company_Name of first 10 jobs data on the website\n",
    "    for k in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "        Company_Name.append(k.text)\n",
    "\n",
    "        \n",
    "        \n",
    "#Job Description of first 10 jobs data on the website\n",
    "\n",
    "#connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Acer\\Desktop\\Internship 11 - Project 1 - Avinash Carneiro\\chromedriver.exe\")\n",
    "\n",
    "#Specifying the url of the webpage\n",
    "url1=\"https://www.naukri.com/job-listings-data-scientist-data-analyst-immediate-caia-center-for-artificial-intelligence-advanced-analytics-chennai-pune-bengaluru-bangalore-hyderabad-secunderabad-0-to-3-years-210920000599?src=jobsearchDesk&sid=1611173670729703&xp=1&px=1\"\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url1)\n",
    "Job_Description1=[]\n",
    "#Job Description of the data on the website\n",
    "for i in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='dang-inner-html']\"):\n",
    "        Job_Description1.append(i.text.replace('\\r\\n','').replace('\\n',''))\n",
    "\n",
    "\n",
    "#Specifying the url of the webpage\n",
    "url2=\"https://www.naukri.com/job-listings-hcl-hiring-data-scientist-with-exp-in-machine-learning-sql-bangalore-hcl-technologies-limited-bengaluru-bangalore-5-to-10-years-190121001223?src=jobsearchDesk&sid=1611173670729703&xp=2&px=1\"\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url2)\n",
    "Job_Description2=[]\n",
    "#Job Description of the data on the website\n",
    "for i in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='dang-inner-html']\"):\n",
    "        Job_Description2.append(i.text.replace('\\r\\n','').replace('\\n',''))\n",
    "\n",
    "        \n",
    "#Specifying the url of the webpage\n",
    "url3=\"https://www.naukri.com/job-listings-data-scientist-machine-learning-augmatrixgo-bengaluru-bangalore-2-to-5-years-140121905423?src=jobsearchDesk&sid=1611173670729703&xp=3&px=1\"\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url3)\n",
    "Job_Description3=[]\n",
    "#Job Description of the data on the website\n",
    "for i in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='dang-inner-html']\"):\n",
    "        Job_Description3.append(i.text.replace('\\r\\n','').replace('\\n',''))\n",
    "        \n",
    "        \n",
    "#Specifying the url of the webpage\n",
    "url4=\"https://www.naukri.com/job-listings-data-scientist-machine-learning-blue-yonder-india-private-limited-bengaluru-bangalore-5-to-8-years-130121902169?src=jobsearchDesk&sid=1611173670729703&xp=4&px=1\"\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url4)\n",
    "Job_Description4=[]\n",
    "#Job Description of the data on the website\n",
    "for i in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='clearboth description']\"):\n",
    "        Job_Description4.append(i.text.replace('\\r\\n','').replace('\\n',''))\n",
    "\n",
    "        \n",
    "#Specifying the url of the webpage\n",
    "url5=\"https://www.naukri.com/job-listings-data-scientist-machine-learning-blue-yonder-india-private-limited-bengaluru-bangalore-3-to-5-years-130121902167?src=jobsearchDesk&sid=1611173670729703&xp=5&px=1\"\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url5)\n",
    "Job_Description5=[]\n",
    "#Job Description of the data on the website\n",
    "for i in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='clearboth description']\"):\n",
    "        Job_Description5.append(i.text.replace('\\r\\n','').replace('\\n',''))\n",
    "\n",
    "        \n",
    "#Specifying the url of the webpage\n",
    "url6=\"https://www.naukri.com/job-listings-senior-associate-data-scientist-ml-engineer-pricewaterhouse-coopers-private-limited-bengaluru-bangalore-3-to-8-years-080121501399?src=jobsearchDesk&sid=1611173670729703&xp=6&px=1\"\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url6)\n",
    "Job_Description6=[]\n",
    "#Job Description of the data on the website\n",
    "for i in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='dang-inner-html']\"):\n",
    "        Job_Description6.append(i.text.replace('\\r\\n','').replace('\\n',''))\n",
    "\n",
    "        \n",
    "#Specifying the url of the webpage\n",
    "url7=\"https://www.naukri.com/job-listings-senior-data-scientist-philips-india-limited-bengaluru-bangalore-8-to-12-years-110121501358?src=jobsearchDesk&sid=1611173670729703&xp=7&px=1\"\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url7)\n",
    "Job_Description7=[]\n",
    "#Job Description of the data on the website\n",
    "for i in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='dang-inner-html']\"):\n",
    "        Job_Description7.append(i.text.replace('\\r\\n','').replace('\\n',''))       \n",
    "        \n",
    "\n",
    "#Specifying the url of the webpage\n",
    "url8=\"https://www.naukri.com/job-listings-data-scientist-machine-learning-remote-working-doji-ltd-delhi-ncr-bengaluru-bangalore-anywhere-in-india-2-to-5-years-171220006270?src=jobsearchDesk&sid=1611173670729703&xp=8&px=1\"\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url8)\n",
    "Job_Description8=[]\n",
    "#Job Description of the data on the website\n",
    "for i in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='dang-inner-html']\"):\n",
    "        Job_Description8.append(i.text.replace('\\r\\n','').replace('\\n',''))\n",
    "        \n",
    "\n",
    "#Specifying the url of the webpage\n",
    "url9=\"https://www.naukri.com/job-listings-software-developer-data-scientist-nlp-machine-learning-cunesoft-india-private-limited-bengaluru-bangalore-3-to-6-years-190121001281?src=jobsearchDesk&sid=1611173670729703&xp=9&px=1\"\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url9)\n",
    "Job_Description9=[]\n",
    "#Job Description of the data on the website\n",
    "for i in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='dang-inner-html']\"):\n",
    "        Job_Description9.append(i.text.replace('\\r\\n','').replace('\\n',''))\n",
    "        \n",
    "        \n",
    "#Specifying the url of the webpage\n",
    "url10=\"https://www.naukri.com/job-listings-sr-data-scientist-netapp-india-private-limited-bengaluru-bangalore-10-to-15-years-080121903902?src=jobsearchDesk&sid=1611173670729703&xp=10&px=1\"\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url10)\n",
    "Job_Description10=[]\n",
    "#Job Description of the data on the website\n",
    "for i in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='f14 lh18 alignJ disc-li']\"):\n",
    "        Job_Description10.append(i.text.replace('\\r\\n','').replace('\\n',''))\n",
    "        \n",
    "#Adding all the Job_Descriptions of the mentoined jobs\n",
    "Job_Description=(Job_Description1 + Job_Description2 + Job_Description3 + Job_Description4 + Job_Description5 + Job_Description6 + Job_Description7 + Job_Description8 + Job_Description9 + Job_Description10)\n",
    "\n",
    "        \n",
    "#Jobs_Title of first 10 jobs       \n",
    "Jobs_Title=Jobs_Title[0:10]\n",
    "print('Job_Titles :', Jobs_Title)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Job_Location of first 10 jobs\n",
    "Job_Location=Job_Location[0:10]\n",
    "print('Job_Location :', Job_Location)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Company_Name of first 10 jobs\n",
    "Company_Name=Company_Name[0:10]\n",
    "print('Company_Name :', Company_Name)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Job_Description of first 10 jobs\n",
    "Job_Description=Job_Description[0:10]\n",
    "print('Job_Description :', Job_Description[0:3])\n",
    "print(\"\\n\")\n",
    "\n",
    "#Length of the lists\n",
    "print('Lenght of Jobs_Title :', len(Jobs_Title)), print('Lenght of Job_Location :', len(Job_Location)),\n",
    "print('Lenght of Company_Name :', len(Company_Name)), print('Lenght of Job_Description :', len(Job_Description))\n",
    "\n",
    "import pandas as pd\n",
    "Data_Scientist=pd.DataFrame({})\n",
    "\n",
    "#Creating dataFrame to save the scraped data of Analyst jobs (job-title, job-location, company_name, Job_Description)\n",
    "Data_Scientist['Job Title']=Jobs_Title\n",
    "Data_Scientist['Job Location']=Job_Location\n",
    "Data_Scientist['Company Name']=Company_Name\n",
    "Data_Scientist['Job Description']=Job_Description\n",
    "print(\"\\n\")\n",
    "\n",
    "print('The DataFrame for First 10 Data_Scientist Jobs on https://www.naukri.com/ is :')\n",
    "Data_Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: Scraping data using the filters available on the webpage https://www.naukri.com/ as shown & scraping the job-title, job-location, company_name, experience_required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job_Titles : ['Data Scientist - Python/Machine Learning', 'Tech Mahindra hiring For Data Scientist- Noida', 'Data Scientist - Commercial Planning and Analysis', 'Data Scientist', 'Data Scientist - Machine Learning/ Artificial Intelligence - IT', 'GCP Skilled Analytics Resources (Data engineer / Data scientists)', 'Data Scientist', 'Data Scientist Machine Learning', 'Data Scientist', 'Business Analyst - Data Scientist']\n",
      "\n",
      "\n",
      "Job_Location : ['Noida', 'Noida', 'Delhi NCR, Gurgaon', 'Faridabad, Delhi NCR, Ghaziabad', 'Delhi/NCR Delhi NCR, Noida', 'Pune, Bengaluru, Gurgaon', 'Gurgaon Gurugram', 'Gurgaon', 'Delhi NCR', 'Gurgaon']\n",
      "\n",
      "\n",
      "Company_Name : ['Jubna', 'tech mahindra ltd', 'Air Asia India Limited', 'Amity University', 'Talent Acceleration Corridor', 'Aerial Telecom Solutions Pvt. Ltd.', 'IBM India Pvt. Limited', 'Delhivery', 'Eighteen Pixels India Private Limited', 'HyreFox Consultants Pvt Ltd']\n",
      "\n",
      "\n",
      "Experience_Required : ['5-8 Yrs', '5-10 Yrs', '1-6 Yrs', '6-8 Yrs', '6-11 Yrs', '3-8 Yrs', '3-5 Yrs', '1-3 Yrs', '2-6 Yrs', '3-5 Yrs']\n",
      "\n",
      "\n",
      "Lenght of Jobs_Title : 10\n",
      "Lenght of Job_Location : 10\n",
      "Lenght of Company_Name : 10\n",
      "Lenght of Experience_Required : 10\n",
      "\n",
      "\n",
      "The DataFrame for First 10 Data_Scientists Jobs on https://www.naukri.com/ with the \"location filter - “Delhi/NCRis & salary filter - “3-6” lakhs is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Python/Machine Learning</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Jubna</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tech Mahindra hiring For Data Scientist- Noida</td>\n",
       "      <td>Noida</td>\n",
       "      <td>tech mahindra ltd</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Commercial Planning and Analysis</td>\n",
       "      <td>Delhi NCR, Gurgaon</td>\n",
       "      <td>Air Asia India Limited</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Faridabad, Delhi NCR, Ghaziabad</td>\n",
       "      <td>Amity University</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Machine Learning/ Artificial ...</td>\n",
       "      <td>Delhi/NCR Delhi NCR, Noida</td>\n",
       "      <td>Talent Acceleration Corridor</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GCP Skilled Analytics Resources (Data engineer...</td>\n",
       "      <td>Pune, Bengaluru, Gurgaon</td>\n",
       "      <td>Aerial Telecom Solutions Pvt. Ltd.</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist Machine Learning</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi NCR</td>\n",
       "      <td>Eighteen Pixels India Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business Analyst - Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>HyreFox Consultants Pvt Ltd</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0           Data Scientist - Python/Machine Learning   \n",
       "1     Tech Mahindra hiring For Data Scientist- Noida   \n",
       "2  Data Scientist - Commercial Planning and Analysis   \n",
       "3                                     Data Scientist   \n",
       "4  Data Scientist - Machine Learning/ Artificial ...   \n",
       "5  GCP Skilled Analytics Resources (Data engineer...   \n",
       "6                                     Data Scientist   \n",
       "7                    Data Scientist Machine Learning   \n",
       "8                                     Data Scientist   \n",
       "9                  Business Analyst - Data Scientist   \n",
       "\n",
       "                      Job Location                           Company Name  \\\n",
       "0                            Noida                                  Jubna   \n",
       "1                            Noida                      tech mahindra ltd   \n",
       "2               Delhi NCR, Gurgaon                 Air Asia India Limited   \n",
       "3  Faridabad, Delhi NCR, Ghaziabad                       Amity University   \n",
       "4       Delhi/NCR Delhi NCR, Noida           Talent Acceleration Corridor   \n",
       "5         Pune, Bengaluru, Gurgaon     Aerial Telecom Solutions Pvt. Ltd.   \n",
       "6                 Gurgaon Gurugram                 IBM India Pvt. Limited   \n",
       "7                          Gurgaon                              Delhivery   \n",
       "8                        Delhi NCR  Eighteen Pixels India Private Limited   \n",
       "9                          Gurgaon            HyreFox Consultants Pvt Ltd   \n",
       "\n",
       "  Experience Required  \n",
       "0             5-8 Yrs  \n",
       "1            5-10 Yrs  \n",
       "2             1-6 Yrs  \n",
       "3             6-8 Yrs  \n",
       "4            6-11 Yrs  \n",
       "5             3-8 Yrs  \n",
       "6             3-5 Yrs  \n",
       "7             1-3 Yrs  \n",
       "8             2-6 Yrs  \n",
       "9             3-5 Yrs  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Acer\\Desktop\\Internship 11 - Project 1 - Avinash Carneiro\\chromedriver.exe\")\n",
    "\n",
    "#Specifying the url of the webpage\n",
    "url=\"https://www.naukri.com/data-scientist-jobs?k=data%20scientist&cityType=25.9.31&ctcFilter=3to6\"\n",
    "\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url)\n",
    "\n",
    "#Lets create 4 empty lists\n",
    "Jobs_Title=[]\n",
    "Job_Location=[]\n",
    "Company_Name=[]\n",
    "Experience_Required=[]\n",
    "\n",
    "\n",
    "#Jobs_Title of first 10 jobs data on the website\n",
    "for i in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "        Jobs_Title.append(i.text)\n",
    "\n",
    "#Job_Location of first 10 jobs data on the website\n",
    "    for j in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\"):\n",
    "        Job_Location.append(j.text)\n",
    "\n",
    "#Company_Name of first 10 jobs data on the website\n",
    "    for k in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "        Company_Name.append(k.text)\n",
    "\n",
    "#Experience_Required of first 10 jobs data on the website\n",
    "    for l in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\"):\n",
    "        Experience_Required.append(l.text)\n",
    "        \n",
    "#Jobs_Title of first 10 jobs       \n",
    "Jobs_Title=Jobs_Title[0:10]\n",
    "print('Job_Titles :', Jobs_Title)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Job_Location of first 10 jobs\n",
    "Job_Location=Job_Location[0:10]\n",
    "print('Job_Location :', Job_Location)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Company_Name of first 10 jobs\n",
    "Company_Name=Company_Name[0:10]\n",
    "print('Company_Name :', Company_Name)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Experience_Required of first 10 jobs\n",
    "Experience_Required=Experience_Required[0:10]\n",
    "print('Experience_Required :', Experience_Required)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Length of the lists\n",
    "print('Lenght of Jobs_Title :', len(Jobs_Title)), print('Lenght of Job_Location :', len(Job_Location)),\n",
    "print('Lenght of Company_Name :', len(Company_Name)), print('Lenght of Experience_Required :', len(Experience_Required))\n",
    "\n",
    "import pandas as pd\n",
    "Data_Scientists=pd.DataFrame({})\n",
    "\n",
    "#Creating dataFrame to save the scraped data of Analyst jobs (job-title, job-location, company_name, experience_required)\n",
    "Data_Scientists['Job Title']=Jobs_Title\n",
    "Data_Scientists['Job Location']=Job_Location\n",
    "Data_Scientists['Company Name']=Company_Name\n",
    "Data_Scientists['Experience Required']=Experience_Required\n",
    "print(\"\\n\")\n",
    "\n",
    "print('The DataFrame for First 10 Data_Scientists Jobs on https://www.naukri.com/ with the \"location filter - “Delhi/NCRis & salary filter - “3-6” lakhs is:')\n",
    "Data_Scientists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company_Name : ['DcodeAI', 'QuantumIT', 'Salasar New Age Technologies', 'Biz2Credit Inc', 'Salasar New Age Technologies', 'Techlive', 'Emerging India Group', 'Dürr Somac GmbH', 'THSTI', 'adidas']\n",
      "\n",
      "\n",
      "Jobs_Title : ['Artificial Intelligence Product Designer', 'Data science', 'Data Scientist Intern', 'Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Scientist', 'Machine Learning Engineer/ Data Scientist', 'Data Scientist', 'Jr Data Scientist']\n",
      "\n",
      "\n",
      "Job_Posted : ['14d', '8d', '30d+', '30d+', '30d+', '30d+', '19d', '30d+', '15d', '5d']\n",
      "\n",
      "\n",
      "Company_Rating : ['3.3', '3.7', '5', '3.9', '3.9', '3.6', '4.2', '3.8', '4.2', '3']\n",
      "\n",
      "\n",
      "Lenght of Company_Name : 10\n",
      "Lenght of Jobs_Title : 10\n",
      "Lenght of Job_Posted : 10\n",
      "Lenght of Company_Rating : 10\n",
      "\n",
      "\n",
      "The DataFrame for First 10 Data_Scientists Jobs on https://www.glassdoor.co.in/ is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Jobs Title</th>\n",
       "      <th>Job Posted</th>\n",
       "      <th>Company Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DcodeAI</td>\n",
       "      <td>Artificial Intelligence Product Designer</td>\n",
       "      <td>14d</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QuantumIT</td>\n",
       "      <td>Data science</td>\n",
       "      <td>8d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>30d+</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Emerging India Group</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>19d</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dürr Somac GmbH</td>\n",
       "      <td>Machine Learning Engineer/ Data Scientist</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>THSTI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>15d</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>adidas</td>\n",
       "      <td>Jr Data Scientist</td>\n",
       "      <td>5d</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Company Name                                 Jobs Title  \\\n",
       "0                       DcodeAI   Artificial Intelligence Product Designer   \n",
       "1                     QuantumIT                               Data science   \n",
       "2  Salasar New Age Technologies                      Data Scientist Intern   \n",
       "3                Biz2Credit Inc                             Data Scientist   \n",
       "4  Salasar New Age Technologies                             Data Scientist   \n",
       "5                      Techlive                             Data Scientist   \n",
       "6          Emerging India Group                             Data Scientist   \n",
       "7               Dürr Somac GmbH  Machine Learning Engineer/ Data Scientist   \n",
       "8                         THSTI                             Data Scientist   \n",
       "9                        adidas                          Jr Data Scientist   \n",
       "\n",
       "  Job Posted Company Rating  \n",
       "0        14d            3.3  \n",
       "1         8d            3.7  \n",
       "2       30d+              5  \n",
       "3       30d+            3.9  \n",
       "4       30d+            3.9  \n",
       "5       30d+            3.6  \n",
       "6        19d            4.2  \n",
       "7       30d+            3.8  \n",
       "8        15d            4.2  \n",
       "9         5d              3  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Acer\\Desktop\\Internship 11 - Project 1 - Avinash Carneiro\\chromedriver.exe\")\n",
    "\n",
    "#Specifying the url of the webpage\n",
    "url=\"https://www.glassdoor.co.in/Job/noida-data-scientist-jobs-SRCH_IL.0,5_IC4477468_KO6,20.htm\"\n",
    "\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url)\n",
    "\n",
    "#Lets create 4 empty lists\n",
    "\n",
    "Company_Name=[]\n",
    "Jobs_Title=[]\n",
    "Job_Posted=[]\n",
    "Company_Rating=[]\n",
    "\n",
    "\n",
    "#Jobs_Title of first 10 jobs data on the website\n",
    "for i in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='jobHeader d-flex justify-content-between align-items-start']\"):\n",
    "        Company_Name.append(i.text)\n",
    "\n",
    "#Jobs_Title of first 10 jobs data on the website\n",
    "for i in range(0, 1):\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='jobInfoItem jobTitle css-13w0lq6 eigr9kq1 jobLink']\"):\n",
    "        Jobs_Title.append(j.text)\n",
    "\n",
    "#Company_Name of first 10 jobs data on the website\n",
    "    for k in driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\"):\n",
    "        Job_Posted.append(k.text)\n",
    "\n",
    "#Experience_Required of first 10 jobs data on the website\n",
    "    for l in driver.find_elements_by_xpath(\"//span[@class='compactStars ']\"):\n",
    "        Company_Rating.append(l.text)\n",
    "        \n",
    "#Jobs_Title of first 10 jobs       \n",
    "Company_Name=Company_Name[0:10]\n",
    "print('Company_Name :', Company_Name)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Job_Location of first 10 jobs\n",
    "Jobs_Title=Jobs_Title[0:10]\n",
    "print('Jobs_Title :', Jobs_Title)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Company_Name of first 10 jobs\n",
    "Job_Posted=Job_Posted[0:10]\n",
    "print('Job_Posted :', Job_Posted)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Experience_Required of first 10 jobs\n",
    "Company_Rating=Company_Rating[0:10]\n",
    "print('Company_Rating :', Company_Rating)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Length of the lists\n",
    "print('Lenght of Company_Name :', len(Company_Name)), print('Lenght of Jobs_Title :', len(Jobs_Title)),\n",
    "print('Lenght of Job_Posted :', len(Job_Posted)), print('Lenght of Company_Rating :', len(Company_Rating))\n",
    "\n",
    "import pandas as pd\n",
    "Data_Scientist_Glassdoor=pd.DataFrame({})\n",
    "\n",
    "#Creating dataFrame to save the scraped data of Data_Scientist_Glassdoor jobs.\n",
    "Data_Scientist_Glassdoor['Company Name']=Company_Name\n",
    "Data_Scientist_Glassdoor['Jobs Title']=Jobs_Title\n",
    "Data_Scientist_Glassdoor['Job Posted']=Job_Posted\n",
    "Data_Scientist_Glassdoor['Company Rating']=Company_Rating\n",
    "print(\"\\n\")\n",
    "\n",
    "print('The DataFrame for First 10 Data_Scientists Jobs on https://www.glassdoor.co.in/ is:')\n",
    "Data_Scientist_Glassdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company_Name : ['Delhivery', 'Accenture', 'Ericsson-Worldwide', 'Tata Consultancy Services', 'IBM', 'UnitedHealth Group', 'Valiance Solutions', 'Innovaccer', 'Cognizant Technology Solutions', 'ZS Associates']\n",
      "\n",
      "\n",
      "Number_of_salaries : ['13 salaries', '10 salaries', '10 salaries', '9 salaries', '9 salaries', '8 salaries', '8 salaries', '7 salaries', '6 salaries', '5 salaries']\n",
      "\n",
      "\n",
      "Average_Salary : ['₹ 12,81,419/yr', '₹ 9,98,925/yr', '₹ 7,90,026/yr', '₹ 6,02,000/yr', '₹ 7,71,657/yr', '₹ 12,22,902/yr', '₹ 7,91,015/yr', '₹ 12,15,138/yr', '₹ 10,21,889/yr', '₹ 10,00,000/yr']\n",
      "\n",
      "\n",
      "              Salary\n",
      "0  [₹456K, ₹11,789K]\n",
      "1   [₹585K, ₹2,200K]\n",
      "2   [₹420K, ₹1,636K]\n",
      "3   [₹336K, ₹1,024K]\n",
      "4   [₹595K, ₹2,769K]\n",
      "5   [₹727K, ₹1,597K]\n",
      "6   [₹509K, ₹1,168K]\n",
      "7   [₹629K, ₹1,719K]\n",
      "8   [₹804K, ₹1,281K]\n",
      "9   [₹205K, ₹1,835K]\n",
      "\n",
      "\n",
      "Lenght of Company_Name : 10\n",
      "Lenght of Number_of_salaries : 10\n",
      "Lenght of Average_Salary : 10\n",
      "\n",
      "\n",
      "The DataFrame for First 10 Data_Scientists Glassdoor_Salary on https://www.glassdoor.co.in/ is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Number of Salaries</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>13 salaries</td>\n",
       "      <td>₹ 12,81,419/yr</td>\n",
       "      <td>₹456K</td>\n",
       "      <td>₹11,789K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹ 9,98,925/yr</td>\n",
       "      <td>₹585K</td>\n",
       "      <td>₹2,200K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹ 7,90,026/yr</td>\n",
       "      <td>₹420K</td>\n",
       "      <td>₹1,636K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹ 6,02,000/yr</td>\n",
       "      <td>₹336K</td>\n",
       "      <td>₹1,024K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IBM</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹ 7,71,657/yr</td>\n",
       "      <td>₹595K</td>\n",
       "      <td>₹2,769K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 12,22,902/yr</td>\n",
       "      <td>₹727K</td>\n",
       "      <td>₹1,597K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 7,91,015/yr</td>\n",
       "      <td>₹509K</td>\n",
       "      <td>₹1,168K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>7 salaries</td>\n",
       "      <td>₹ 12,15,138/yr</td>\n",
       "      <td>₹629K</td>\n",
       "      <td>₹1,719K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>6 salaries</td>\n",
       "      <td>₹ 10,21,889/yr</td>\n",
       "      <td>₹804K</td>\n",
       "      <td>₹1,281K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>5 salaries</td>\n",
       "      <td>₹ 10,00,000/yr</td>\n",
       "      <td>₹205K</td>\n",
       "      <td>₹1,835K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Company Name Number of Salaries  Average Salary  \\\n",
       "0                       Delhivery        13 salaries  ₹ 12,81,419/yr   \n",
       "1                       Accenture        10 salaries   ₹ 9,98,925/yr   \n",
       "2              Ericsson-Worldwide        10 salaries   ₹ 7,90,026/yr   \n",
       "3       Tata Consultancy Services         9 salaries   ₹ 6,02,000/yr   \n",
       "4                             IBM         9 salaries   ₹ 7,71,657/yr   \n",
       "5              UnitedHealth Group         8 salaries  ₹ 12,22,902/yr   \n",
       "6              Valiance Solutions         8 salaries   ₹ 7,91,015/yr   \n",
       "7                      Innovaccer         7 salaries  ₹ 12,15,138/yr   \n",
       "8  Cognizant Technology Solutions         6 salaries  ₹ 10,21,889/yr   \n",
       "9                   ZS Associates         5 salaries  ₹ 10,00,000/yr   \n",
       "\n",
       "  Min Salary Max Salary  \n",
       "0      ₹456K   ₹11,789K  \n",
       "1      ₹585K    ₹2,200K  \n",
       "2      ₹420K    ₹1,636K  \n",
       "3      ₹336K    ₹1,024K  \n",
       "4      ₹595K    ₹2,769K  \n",
       "5      ₹727K    ₹1,597K  \n",
       "6      ₹509K    ₹1,168K  \n",
       "7      ₹629K    ₹1,719K  \n",
       "8      ₹804K    ₹1,281K  \n",
       "9      ₹205K    ₹1,835K  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "#connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Acer\\Desktop\\Internship 11 - Project 1 - Avinash Carneiro\\chromedriver.exe\")\n",
    "\n",
    "#Specifying the url of the webpage\n",
    "url=\"https://www.glassdoor.co.in/Salaries/new-delhi-data-scientist-salary-SRCH_IL.0,9_IM1083_KO10,24.htm?clickSource=searchBtn\"\n",
    "\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url)\n",
    "\n",
    "#Lets create 4 empty lists\n",
    "\n",
    "Company_Name=[]\n",
    "Number_of_salaries=[]\n",
    "Average_Salary=[]\n",
    "Salary=[]\n",
    "\n",
    "\n",
    "#Jobs_Title of first 10 jobs data on the website\n",
    "for i in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//p[@class='m-0 ']\"):\n",
    "        Company_Name.append(i.text)\n",
    "\n",
    "#Number_of_salaries of first 10 jobs data on the website\n",
    "    for j in driver.find_elements_by_xpath(\"//p[@class='css-1uyte9r css-1kuy7z7 m-0 ']\"):\n",
    "        Number_of_salaries.append(j.text.replace('\\r\\n','').replace('\\n',''))\n",
    "\n",
    "#Average_Salary of first 10 jobs data on the website\n",
    "    for k in driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']\"):\n",
    "        Average_Salary.append(k.text.replace('\\r\\n','').replace('\\n',''))\n",
    "        \n",
    "\n",
    "#Min_Salary & Max_Salary of first 10 jobs data on the website\n",
    "Salary_Tags=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']\")\n",
    "for l in Salary_Tags:\n",
    "    salary=l.text\n",
    "    Salary.append(salary.split('\\n'))\n",
    "Salary[0:10]\n",
    "        \n",
    "#Jobs_Title of first 10 jobs       \n",
    "Company_Name=Company_Name[0:10]\n",
    "print('Company_Name :', Company_Name)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Number_of_salaries of first 10 jobs\n",
    "Number_of_salaries=Number_of_salaries[0:10]\n",
    "print('Number_of_salaries :', Number_of_salaries)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Average_Salary of first 10 jobs\n",
    "Average_Salary=Average_Salary[0:10]\n",
    "print('Average_Salary :', Average_Salary)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Creating dataframe for Salary list\n",
    "DF=pd.DataFrame({})\n",
    "DF['Salary']=Salary\n",
    "print(DF.head(10))\n",
    "print(\"\\n\")\n",
    "\n",
    "#Length of the lists\n",
    "print('Lenght of Company_Name :', len(Company_Name)), print('Lenght of Number_of_salaries :', len(Number_of_salaries)),\n",
    "print('Lenght of Average_Salary :', len(Average_Salary))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "Glassdoor_Salary=pd.DataFrame({})\n",
    "\n",
    "#Creating dataFrame to save the scraped data of Analyst jobs (job-title, job-location, company_name, experience_required)\n",
    "Glassdoor_Salary['Company Name']=Company_Name\n",
    "Glassdoor_Salary['Number of Salaries']=Number_of_salaries\n",
    "Glassdoor_Salary['Average Salary']=Average_Salary\n",
    "#Creating Columns for Minimum_Salary\n",
    "Glassdoor_Salary['Min Salary']=DF['Salary'].str[:1]\n",
    "Glassdoor_Salary['Min Salary'] = Glassdoor_Salary['Min Salary'].str.get(0)\n",
    "\n",
    "#Creating Columns for Maximum_Salary\n",
    "Glassdoor_Salary['Max Salary']=DF['Salary'].str[1:]\n",
    "Glassdoor_Salary['Max Salary'] = Glassdoor_Salary['Max Salary'].str.get(0)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print('The DataFrame for First 10 Data_Scientists Glassdoor_Salary on https://www.glassdoor.co.in/ is:')\n",
    "Glassdoor_Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand_Name : 100\n",
      "Product_Description : 100\n",
      "Price : 100\n",
      "Discount : 100\n",
      "\n",
      "\n",
      "The DataFrame for First 100 Sunglasses on https://www.flipkart.com/ is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Product_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA COLLECTION</td>\n",
       "      <td>₹188</td>\n",
       "      <td>87% off</td>\n",
       "      <td>Gradient, Mirrored, UV Protection Round, Round...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FDA COLLECTION</td>\n",
       "      <td>₹251</td>\n",
       "      <td>83% off</td>\n",
       "      <td>Gradient, UV Protection Round, Round, Round Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDA COLLECTION</td>\n",
       "      <td>₹199</td>\n",
       "      <td>84% off</td>\n",
       "      <td>Gradient, Mirrored, UV Protection Round, Round...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shah collections</td>\n",
       "      <td>₹219</td>\n",
       "      <td>78% off</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phenomenal</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "      <td>UV Protection, Mirrored Retro Square Sunglasse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹645</td>\n",
       "      <td>19% off</td>\n",
       "      <td>Night Vision, Polarized, UV Protection, Riding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>FDA COLLECTION</td>\n",
       "      <td>₹188</td>\n",
       "      <td>87% off</td>\n",
       "      <td>Polarized, Mirrored, UV Protection Retro Squar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>₹449</td>\n",
       "      <td>79% off</td>\n",
       "      <td>UV Protection Spectacle Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Royal Son</td>\n",
       "      <td>₹279</td>\n",
       "      <td>78% off</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>STYLE GURU</td>\n",
       "      <td>₹799</td>\n",
       "      <td>77% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Brand Name Price Discount  \\\n",
       "0     FDA COLLECTION  ₹188  87% off   \n",
       "1     FDA COLLECTION  ₹251  83% off   \n",
       "2     FDA COLLECTION  ₹199  84% off   \n",
       "3   shah collections  ₹219  78% off   \n",
       "4         Phenomenal  ₹399  80% off   \n",
       "..               ...   ...      ...   \n",
       "95          Fastrack  ₹645  19% off   \n",
       "96    FDA COLLECTION  ₹188  87% off   \n",
       "97    ROZZETTA CRAFT  ₹449  79% off   \n",
       "98         Royal Son  ₹279  78% off   \n",
       "99        STYLE GURU  ₹799  77% off   \n",
       "\n",
       "                                  Product_Description  \n",
       "0   Gradient, Mirrored, UV Protection Round, Round...  \n",
       "1   Gradient, UV Protection Round, Round, Round Su...  \n",
       "2   Gradient, Mirrored, UV Protection Round, Round...  \n",
       "3   UV Protection, Polarized, Mirrored Rectangular...  \n",
       "4   UV Protection, Mirrored Retro Square Sunglasse...  \n",
       "..                                                ...  \n",
       "95  Night Vision, Polarized, UV Protection, Riding...  \n",
       "96  Polarized, Mirrored, UV Protection Retro Squar...  \n",
       "97     UV Protection Spectacle Sunglasses (Free Size)  \n",
       "98  Gradient, UV Protection Wayfarer Sunglasses (F...  \n",
       "99       UV Protection Aviator Sunglasses (Free Size)  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "#connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Acer\\Desktop\\Internship 11 - Project 1 - Avinash Carneiro\\chromedriver.exe\")\n",
    "\n",
    "#Specifying the url of the webpage\n",
    "url=\"https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\"\n",
    "\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url)\n",
    "\n",
    "#Lets create 4 empty lists\n",
    "\n",
    "Brand_Name=[]\n",
    "Product_Description=[]\n",
    "Price=[]\n",
    "Discount=[]\n",
    "\n",
    "\n",
    "#Brand_Name of the sunglasses\n",
    "for i in range(0, 3):\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "        Brand_Name.append(i.text)\n",
    "        \n",
    "#Product_Description of the sunglasses\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        if j is not None:\n",
    "            Product_Description.append(j.text)\n",
    "        else:\n",
    "            Product_Description('_')\n",
    "\n",
    "#Price of of the sunglasses\n",
    "    for k in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        Price.append(k.text)\n",
    "\n",
    "#Discount of of the sunglasses\n",
    "    for k in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\"):\n",
    "        Discount.append(k.text)\n",
    "        \n",
    "    driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\").click()\n",
    "    time.sleep(3)\n",
    "        \n",
    "\n",
    "#Brand_Name of first 10 jobs       \n",
    "Brand_Name=Brand_Name[0:100]\n",
    "Product_Description=Product_Description[0:100]\n",
    "Price=Price[0:100]\n",
    "Discount=Discount[0:100]\n",
    "\n",
    "\n",
    "print('Brand_Name :', len(Brand_Name)), print('Product_Description :', len(Product_Description)),\n",
    "print('Price :', len(Price)), print('Discount :', len(Discount))\n",
    "\n",
    "#Creating dataFrame to save the scraped data of Flipkart_Review\n",
    "import pandas as pd\n",
    "Flipkart_Sunglass=pd.DataFrame({})\n",
    "Flipkart_Sunglass['Brand Name']=Brand_Name\n",
    "Flipkart_Sunglass['Price']=Price\n",
    "Flipkart_Sunglass['Discount']=Discount\n",
    "Flipkart_Sunglass['Product_Description']=Product_Description\n",
    "print(\"\\n\")\n",
    "\n",
    "print('The DataFrame for First 100 Sunglasses on https://www.flipkart.com/ is:')\n",
    "Flipkart_Sunglass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating : 100\n",
      "Review_Summary : 100\n",
      "Full_Review : 100\n",
      "\n",
      "\n",
      "The DataFrame for First 100 Reviews on https://www.flipkart.com/ is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Best budget Iphone till date ❤️ go for it guys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>It’s been almost a month since I have been usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>*Review after 10 months of usage*\\nDoesn't see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Awesome Phone. Slightly high price but worth. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Iphone is just awesome.. battery backup is ver...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rating      Review Summary  \\\n",
       "0      5    Perfect product!   \n",
       "1      5       Great product   \n",
       "2      5  Highly recommended   \n",
       "3      5    Perfect product!   \n",
       "4      5    Perfect product!   \n",
       "5      5   Worth every penny   \n",
       "6      5   Worth every penny   \n",
       "7      5           Wonderful   \n",
       "8      4        Nice product   \n",
       "9      5    Perfect product!   \n",
       "\n",
       "                                         Full Review  \n",
       "0  Amazing phone with great cameras and better ba...  \n",
       "1  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "2  iphone 11 is a very good phone to buy only if ...  \n",
       "3  It’s a must buy who is looking for an upgrade ...  \n",
       "4  Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "5  Best budget Iphone till date ❤️ go for it guys...  \n",
       "6  It’s been almost a month since I have been usi...  \n",
       "7  *Review after 10 months of usage*\\nDoesn't see...  \n",
       "8  Awesome Phone. Slightly high price but worth. ...  \n",
       "9  Iphone is just awesome.. battery backup is ver...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "\n",
    "#connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Acer\\Desktop\\Internship 11 - Project 1 - Avinash Carneiro\\chromedriver.exe\")\n",
    "\n",
    "#Specifying the url of the webpage\n",
    "url=\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3QP11A&marketplace=FLIPKART\"\n",
    "\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url)\n",
    "\n",
    "#Lets create 4 empty lists\n",
    "Rating = []\n",
    "Review_Summary = []\n",
    "Full_Review = []\n",
    "\n",
    "#Rating of the product\n",
    "for i in range(0, 10):\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        Rating.append(i.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        Review_Summary.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\"):\n",
    "        Full_Review.append(k.text)       \n",
    "driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\").click()\n",
    "time.sleep(3)\n",
    "\n",
    "    \n",
    "print('Rating :', len(Rating)), print('Review_Summary :', len(Review_Summary)),\n",
    "print('Full_Review :', len(Full_Review))\n",
    "\n",
    "\n",
    "#Creating dataFrame to save the scraped data of Flipkart_Review\n",
    "import pandas as pd\n",
    "Flipkart_Review=pd.DataFrame({})\n",
    "Flipkart_Review['Rating']=Rating\n",
    "Flipkart_Review['Review Summary']=Review_Summary\n",
    "Flipkart_Review['Full Review']=Full_Review\n",
    "print(\"\\n\")\n",
    "\n",
    "print('The DataFrame for First 100 Reviews on https://www.flipkart.com/ is:')\n",
    "Flipkart_Review.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand_Name : 120\n",
      "Product_Description : 120\n",
      "Price : 120\n",
      "Discount : 120\n",
      "\n",
      "\n",
      "The DataFrame for First 100 Flipkart_Sneakers on https://www.flipkart.com/ is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rockfield</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rockfield</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹378</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stefano Rads</td>\n",
       "      <td>Classy Sneakers For Men</td>\n",
       "      <td>₹289</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Oricum</td>\n",
       "      <td>JESS Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GANPATI TRADERS</td>\n",
       "      <td>Worldcup-03 Running shoes for boys | sports sh...</td>\n",
       "      <td>₹199</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Camfoot</td>\n",
       "      <td>Zar Check Sneakers Sneakers For Men</td>\n",
       "      <td>₹328</td>\n",
       "      <td>47% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Aura</td>\n",
       "      <td>Sneakers For Men  (White) Sneakers For Men</td>\n",
       "      <td>₹794</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bonexy</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brand Name                                Product Description Price  \\\n",
       "0         Rockfield                                   Sneakers For Men  ₹399   \n",
       "1         Rockfield                                   Sneakers For Men  ₹499   \n",
       "2            Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...  ₹499   \n",
       "3      Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men  ₹378   \n",
       "4      Stefano Rads                            Classy Sneakers For Men  ₹289   \n",
       "..              ...                                                ...   ...   \n",
       "95           Oricum                              JESS Sneakers For Men  ₹299   \n",
       "96  GANPATI TRADERS  Worldcup-03 Running shoes for boys | sports sh...  ₹199   \n",
       "97          Camfoot                Zar Check Sneakers Sneakers For Men  ₹328   \n",
       "98             Aura         Sneakers For Men  (White) Sneakers For Men  ₹794   \n",
       "99           Bonexy                                   Sneakers For Men  ₹399   \n",
       "\n",
       "   Discount  \n",
       "0   60% off  \n",
       "1   50% off  \n",
       "2   75% off  \n",
       "3   62% off  \n",
       "4   58% off  \n",
       "..      ...  \n",
       "95  60% off  \n",
       "96  67% off  \n",
       "97  47% off  \n",
       "98  60% off  \n",
       "99  75% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "Brand_Names1=[]\n",
    "Product_Descriptions1=[]\n",
    "Prices1=[]\n",
    "Discounts1=[]\n",
    "Brand_Names2=[]\n",
    "Product_Descriptions2=[]\n",
    "Prices2=[]\n",
    "Discounts2=[]\n",
    "Brand_Names3=[]\n",
    "Product_Descriptions3=[]\n",
    "Prices3=[]\n",
    "Discounts3=[]\n",
    "\n",
    "page1=requests.get(\"https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\")\n",
    "\n",
    "soup1=BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "Brand_Name_Tags=soup1.find_all('div', class_='_2WkVRV')\n",
    "Product_Tags=soup1.find_all('a', class_='IRpwTa')\n",
    "Prices_Tags=soup1.find_all('div', class_='_30jeq3')\n",
    "Discounts_Tags=soup1.find_all('div', class_='_3Ay6Sb')\n",
    "\n",
    "for i in Brand_Name_Tags:\n",
    "    if i is not None:\n",
    "        Brand_Names1.append(i.get_text().replace(\"\\n\", \"\"))\n",
    "    else:\n",
    "        Brand_Names1.replace('Null')\n",
    "Brand_Names1\n",
    "for i in Product_Tags:\n",
    "    Product_Descriptions1.append(i.get_text().replace(\"\\n\", \"\"))\n",
    "Product_Descriptions1\n",
    "for i in Prices_Tags:\n",
    "    Prices1.append(i.get_text().replace(\"\\n\", \"\"))\n",
    "Prices1=Prices1[0:40]\n",
    "for i in Discounts_Tags:\n",
    "    Discounts1.append(i.get_text().replace(\"\\n\", \"\"))\n",
    "Discounts1=Discounts1[0:40]\n",
    "\n",
    "#PAGE 2 \n",
    "page2=requests.get(\"https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=2\")\n",
    "\n",
    "soup2=BeautifulSoup(page2.content, 'html.parser')\n",
    "\n",
    "Brand_Name_Tags=soup2.find_all('div', class_='_2WkVRV')\n",
    "Product_Tags=soup2.find_all('a', class_='IRpwTa')\n",
    "Prices_Tags=soup2.find_all('div', class_='_30jeq3')\n",
    "Discounts_Tags=soup2.find_all('div', class_='_3Ay6Sb')\n",
    "\n",
    "for i in Brand_Name_Tags:\n",
    "    if i is not None:\n",
    "        Brand_Names2.append(i.get_text().replace(\"\\n\", \"\"))\n",
    "    else:\n",
    "        Brand_Names2.replace('Null')\n",
    "Brand_Names2\n",
    "for i in Product_Tags:\n",
    "    Product_Descriptions2.append(i.get_text().replace(\"\\n\", \"\"))\n",
    "Product_Descriptions2\n",
    "for i in Prices_Tags:\n",
    "    Prices2.append(i.get_text().replace(\"\\n\", \"\"))\n",
    "Prices2=Prices2[0:40]\n",
    "for i in Discounts_Tags:\n",
    "    Discounts2.append(i.get_text().replace(\"\\n\", \"\"))\n",
    "Discounts2=Discounts2[0:40]\n",
    "\n",
    "\n",
    "#PAGE 3 \n",
    "page3=requests.get(\"https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=3\")\n",
    "\n",
    "soup3=BeautifulSoup(page3.content, 'html.parser')\n",
    "\n",
    "Brand_Name_Tags=soup3.find_all('div', class_='_2WkVRV')\n",
    "Product_Tags=soup3.find_all('a', class_='IRpwTa')\n",
    "Prices_Tags=soup3.find_all('div', class_='_30jeq3')\n",
    "Discounts_Tags=soup3.find_all('div', class_='_3Ay6Sb')\n",
    "\n",
    "for i in Brand_Name_Tags:\n",
    "    if i is not None:\n",
    "        Brand_Names3.append(i.get_text().replace(\"\\n\", \"\"))\n",
    "    else:\n",
    "        Brand_Names3.replace('Null')\n",
    "Brand_Names3\n",
    "for i in Product_Tags:\n",
    "    Product_Descriptions.append(i.get_text().replace(\"\\n\", \"\"))\n",
    "Product_Descriptions3\n",
    "for i in Prices_Tags:\n",
    "    Prices3.append(i.get_text().replace(\"\\n\", \"\"))\n",
    "Prices3=Prices3[0:40]\n",
    "for i in Discounts_Tags:\n",
    "    Discounts3.append(i.get_text().replace(\"\\n\", \"\"))\n",
    "Discounts3=Discounts3[0:40]\n",
    "\n",
    "#Adding all values in one list\n",
    "Brand_Names=Brand_Names1+Brand_Names2+Brand_Names3\n",
    "Product_Descriptions=Product_Descriptions1+Product_Descriptions2+Product_Descriptions2\n",
    "Prices=Prices1+Prices2+Prices3\n",
    "Discounts=Discounts1+Discounts2+Discounts3\n",
    "\n",
    "#Checking lengths of lists\n",
    "print('Brand_Name :', len(Brand_Names)), print('Product_Description :', len(Product_Descriptions)),\n",
    "print('Price :', len(Prices)), print('Discount :', len(Discounts))\n",
    "\n",
    "#Creating dataFrame to save the scraped data of Flipkart_Review\n",
    "import pandas as pd\n",
    "Flipkart_Sneakers=pd.DataFrame({})\n",
    "Flipkart_Sneakers['Brand Name']=Brand_Names\n",
    "Flipkart_Sneakers['Product Description']=Product_Descriptions\n",
    "Flipkart_Sneakers['Price']=Prices\n",
    "Flipkart_Sneakers['Discount']=Discounts\n",
    "Flipkart_Sneakers=Flipkart_Sneakers.head(100)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('The DataFrame for First 100 Flipkart_Sneakers on https://www.flipkart.com/ is:')\n",
    "Flipkart_Sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9: Go to the link - https://www.myntra.com/shoes Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The DataFrame for First 100 Sunglasses on https://www.myntra.com/shoes is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Shoe_Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>Rs. 6499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN Basketball Shoes</td>\n",
       "      <td>Rs. 9399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men LEGEND REACT 3 Shoes</td>\n",
       "      <td>Rs. 6199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women Air Zoom Pegasus Running</td>\n",
       "      <td>Rs. 7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR MAX VG-R Sneakers</td>\n",
       "      <td>Rs. 6599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR MAX VERONA Sneakers</td>\n",
       "      <td>Rs. 8399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Women Solid Flat Boots</td>\n",
       "      <td>Rs. 7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Woven Design Sneakers</td>\n",
       "      <td>Rs. 6599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Women Solid Sneakers</td>\n",
       "      <td>Rs. 6499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women Air Max Siren Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand Name                Shoe_Description     Price\n",
       "0             ALDO             Men Leather Loafers  Rs. 6499\n",
       "1             Nike     Men JORDAN Basketball Shoes  Rs. 9399\n",
       "2             Nike        Men LEGEND REACT 3 Shoes  Rs. 6199\n",
       "3             Nike  Women Air Zoom Pegasus Running  Rs. 7499\n",
       "4             Nike     Women AIR MAX VG-R Sneakers  Rs. 6599\n",
       "..             ...                             ...       ...\n",
       "95            Nike   Women AIR MAX VERONA Sneakers  Rs. 8399\n",
       "96  Tommy Hilfiger          Women Solid Flat Boots  Rs. 7499\n",
       "97       Cole Haan     Women Woven Design Sneakers  Rs. 6599\n",
       "98            ALDO            Women Solid Sneakers  Rs. 6499\n",
       "99            Nike    Women Air Max Siren Sneakers  Rs. 7999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "#connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Acer\\Desktop\\Internship 11 - Project 1 - Avinash Carneiro\\chromedriver.exe\")\n",
    "\n",
    "#Specifying the url of the webpage\n",
    "url=\"https://www.myntra.com/shoes?plaEnabled=false&rf=Price%3A5899.0_11599.0_5899.0%20TO%2011599.0\"\n",
    "\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url)\n",
    "\n",
    "#Lets create 4 empty lists\n",
    "\n",
    "Brand_Name=[]\n",
    "Shoe_Description=[]\n",
    "Price=[]\n",
    "\n",
    "\n",
    "#Brand_Name of the sunglasses\n",
    "for i in range(0, 3):\n",
    "    for i in driver.find_elements_by_xpath(\"//h3[@class='product-brand']\"):\n",
    "        Brand_Name.append(i.text)\n",
    "        \n",
    "#Product_Description of the sunglasses\n",
    "    for j in driver.find_elements_by_xpath(\"//h4[@class='product-product']\"):\n",
    "        Shoe_Description.append(j.text)\n",
    "\n",
    "#Price of of the sunglasses\n",
    "    for k in driver.find_elements_by_xpath(\"//span[@class='product-discountedPrice']\"):\n",
    "        Price.append(k.text)\n",
    "        \n",
    "    driver.find_element_by_xpath(\"//li[@class='pagination-next']\").click()\n",
    "    time.sleep(3)        \n",
    "\n",
    "\n",
    "#Selecting first 100 shoe details       \n",
    "Brand_Name=Brand_Name[0:100]\n",
    "Shoe_Description=Shoe_Description[0:100]\n",
    "Price=Price[0:100]\n",
    "\n",
    "#Creating dataFrame to save the scraped data of Flipkart_Review\n",
    "import pandas as pd\n",
    "Myntra_Shoes=pd.DataFrame({})\n",
    "Myntra_Shoes['Brand Name']=Brand_Name\n",
    "Myntra_Shoes['Shoe_Description']=Shoe_Description\n",
    "Myntra_Shoes['Price']=Price\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print('The DataFrame for First 100 Sunglasses on https://www.myntra.com/shoes is:')\n",
    "Myntra_Shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The DataFrame for First 10 Laptops on https://www.amazon.in/ is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Avg_Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell Inspiron 5501 15.6 Inch FHD Laptop (10th ...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>85,890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dell Inspiron 5409 14.0\" FHD WVA AG Display 11...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Renewed) Dell Latitude E7470 14-inch Laptop (...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>55,299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54,899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Renewed) Dell Latitude E7470 14-inch Laptop (...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>53,599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MSI GF63 Thin Core i7 9th Gen - (8 GB/512 GB S...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>70,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Renewed) Dell Latitude E7470 14-inch Laptop (...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>52,699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) Dell Latitude E7470 14-inch Laptop (...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>54,399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo Yoga S740 Intel Core i7 10th Gen 14 inc...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>96,450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MSI Gaming GL65 Leopard , Intel 9th Gen. i7-97...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>63,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Avg_Ratings   Price\n",
       "0  Dell Inspiron 5501 15.6 Inch FHD Laptop (10th ...         3.8  85,890\n",
       "1  Dell Inspiron 5409 14.0\" FHD WVA AG Display 11...         3.6  86,990\n",
       "2  (Renewed) Dell Latitude E7470 14-inch Laptop (...         3.3  55,299\n",
       "3  Mi Notebook Horizon Edition 14 Intel Core i5-1...         4.0  54,899\n",
       "4  (Renewed) Dell Latitude E7470 14-inch Laptop (...         4.2  53,599\n",
       "5  MSI GF63 Thin Core i7 9th Gen - (8 GB/512 GB S...         4.2  70,990\n",
       "6  (Renewed) Dell Latitude E7470 14-inch Laptop (...         4.3  52,699\n",
       "7  (Renewed) Dell Latitude E7470 14-inch Laptop (...         3.7  54,399\n",
       "8  Lenovo Yoga S740 Intel Core i7 10th Gen 14 inc...         4.3  96,450\n",
       "9  MSI Gaming GL65 Leopard , Intel 9th Gen. i7-97...         5.0  63,990"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import all libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "#connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Acer\\Desktop\\Internship 11 - Project 1 - Avinash Carneiro\\chromedriver.exe\")\n",
    "\n",
    "#Specifying the url of the webpage\n",
    "url=\"https://www.amazon.in/s?k=Laptop&i=computers&rh=n%3A1375424031%2Cp_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&dc&qid=1611863643&rnid=12598141031&ref=sr_nr_p_n_feature_thirteen_browse-bin_17\"\n",
    "\n",
    "#Lets open the webpage through our web driver\n",
    "driver.get(url)\n",
    "\n",
    "#Lets create 4 empty lists\n",
    "\n",
    "Title=[]\n",
    "Rate=[]\n",
    "Avg_Ratings=[]\n",
    "Price=[]\n",
    "\n",
    "\n",
    "#Title of the Laptops\n",
    "for i in range(0, 1):\n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\"):\n",
    "        Title.append(i.text)\n",
    "        \n",
    "#Price of of the Laptops\n",
    "    for k in driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\"):\n",
    "        Price.append(k.text)\n",
    "        \n",
    "\n",
    "#Now getting the request for webpage server:\n",
    "page = requests.get(\"https://www.amazon.in/s?k=Laptop&i=computers&rh=n%3A1375424031%2Cp_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&dc&qid=1611863643&rnid=12598141031&ref=sr_nr_p_n_feature_thirteen_browse-bin_17\")\n",
    "soup=BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "#ratings of Laptops\n",
    "ratingA=soup.find_all('span', class_='a-icon-alt')\n",
    "for j in ratingA:\n",
    "    Rate.append(j.text)\n",
    "# Skipping first 4 ratings as they are unnecessary data which is added in the list\n",
    "Rate=Rate[4:]\n",
    "\n",
    "# Getting first 3 characters of ratings\n",
    "for l in Rate:\n",
    "    Avg_Ratings.append(l[0:3])\n",
    "\n",
    "\n",
    "#Selecting first 10 Laptops     \n",
    "Title=Title[0:10]\n",
    "Avg_Ratings=Avg_Ratings[0:10]\n",
    "Price=Price[0:10]\n",
    "\n",
    "\n",
    "#Creating dataFrame to save the scraped data of Amazon Laptops\n",
    "import pandas as pd\n",
    "Amazon_laptops=pd.DataFrame({})\n",
    "Amazon_laptops['Title']=Title\n",
    "Amazon_laptops['Avg_Ratings']=Avg_Ratings\n",
    "Amazon_laptops['Price']=Price\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print('The DataFrame for First 10 Laptops on https://www.amazon.in/ is:')\n",
    "Amazon_laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Avg_Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Avg_RatingS1=[]\n",
    "Ratings1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now getting the request for webpage server:\n",
    "page = requests.get(\"https://www.amazon.in/s?k=Laptop&i=computers&rh=n%3A1375424031%2Cp_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&dc&qid=1611863643&rnid=12598141031&ref=sr_nr_p_n_feature_thirteen_browse-bin_17\")\n",
    "soup=BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "#ratings of Laptops\n",
    "rating1=soup.find_all('span', class_='a-icon-alt')\n",
    "for j in rating1:\n",
    "    Ratings1.append(j.text)\n",
    "    \n",
    "# Skipping first 4 ratings as they are unnecessary data which is added in the list\n",
    "Ratings1=Ratings1[4:]\n",
    "\n",
    "# Getting first 3 characters of ratings\n",
    "for p in Ratings1:\n",
    "    Avg_RatingS1.append(p[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rate=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now getting the request for webpage server:\n",
    "page = requests.get(\"https://www.amazon.in/s?k=Laptop&i=computers&rh=n%3A1375424031%2Cp_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&dc&qid=1611863643&rnid=12598141031&ref=sr_nr_p_n_feature_thirteen_browse-bin_17\")\n",
    "soup=BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "#ratings of Laptops\n",
    "ratingA=soup.find_all('span', class_='a-icon-alt')\n",
    "for j in ratingA:\n",
    "    Rate.append(j.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Brand_Name_Tags:\n",
    "    if i is not None:\n",
    "        Ratings.append(i.get_text().replace(\"\\n\", \"\"))\n",
    "    else:\n",
    "        Ratings.replace('Null')\n",
    "Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if j is not None:\n",
    "            Product_Description.append(j.text)\n",
    "        else:\n",
    "            Product_Description('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Product_Description of the Sneakers\n",
    "for i in range(0, 2):\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        if j is not None:\n",
    "            Product_Description.append(j.text)\n",
    "        else:\n",
    "            Product_Description('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Product_Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
